# MVTec Anomaly Detection System

A comprehensive anomaly detection system for industrial quality control using the MVTec dataset. This system implements both PaDiM (Patch Distribution Modeling) and Convolutional Autoencoder approaches for detecting defects in manufactured products.

## üìã Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Training Process](#training-process)
- [Testing Process](#testing-process)
- [Model Implementations](#model-implementations)
- [API and Web Interface](#api-and-web-interface)
- [Docker Setup](#docker-setup)
- [Installation](#installation)
- [Usage](#usage)
- [Performance Metrics](#performance-metrics)

## üéØ Overview

This system provides industrial-grade anomaly detection capabilities for quality control in manufacturing environments. It supports two main approaches:

1. **PaDiM (Patch Distribution Modeling)**: Uses feature extraction from pretrained ResNet to model normal patterns
2. **Convolutional Autoencoder**: Learns to reconstruct normal images and detects anomalies based on reconstruction error

## üèóÔ∏è System Architecture

```
MVTec Anomaly Detection System
‚îú‚îÄ‚îÄ Training Pipeline
‚îÇ   ‚îú‚îÄ‚îÄ Data Loading & Preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ Feature Extraction (PaDiM) / Model Training (Autoencoder)
‚îÇ   ‚îú‚îÄ‚îÄ Statistical Modeling / Weight Optimization
‚îÇ   ‚îî‚îÄ‚îÄ Model Checkpointing
‚îú‚îÄ‚îÄ Inference Pipeline
‚îÇ   ‚îú‚îÄ‚îÄ Model Loading
‚îÇ   ‚îú‚îÄ‚îÄ Threshold Calculation
‚îÇ   ‚îú‚îÄ‚îÄ Image Processing
‚îÇ   ‚îî‚îÄ‚îÄ Anomaly Scoring
‚îî‚îÄ‚îÄ API & Web Interface
    ‚îú‚îÄ‚îÄ REST API Endpoints
    ‚îú‚îÄ‚îÄ Web Dashboard
    ‚îî‚îÄ‚îÄ Real-time Testing
```

## üéì Training Process

### PaDiM Training Process

The PaDiM approach follows these steps:

1. **Feature Extraction**
   - Uses pretrained ResNet-18 as feature extractor
   - Extracts features from layers 1, 2, and 3 (equivalent to ResNet layers 4, 5, 6)
   - Upsamples features to consistent spatial dimensions

2. **Statistical Modeling**
   - Computes mean and covariance statistics for each spatial location
   - Uses Ledoit-Wolf shrinkage for robust covariance estimation
   - Creates multivariate Gaussian distribution for each patch

3. **Training Steps**
   ```python
   # 1. Load normal (good) training images
   train_loader = get_train_loader()
   
   # 2. Extract features from all training images
   for batch in train_loader:
       features = feature_extractor(batch)
       all_features.append(features)
   
   # 3. Compute statistical parameters
   mean, cov = compute_embedding_stats(all_features)
   ```

### Autoencoder Training Process

The Convolutional Autoencoder follows traditional deep learning training:

1. **Architecture**
   - Encoder: 4 convolutional blocks with BatchNorm and ReLU
   - Decoder: 4 deconvolutional blocks with upsampling
   - Bottleneck: Configurable latent dimension (default: 512)

2. **Training Objectives**
   - Minimize reconstruction loss (MSE) on normal images
   - Learn compressed representation of normal patterns
   - Optimize for minimal reconstruction error on good samples

3. **Training Configuration**
   ```python
   # Training hyperparameters
   BATCH_SIZE = 16
   LEARNING_RATE = 1e-4
   EPOCHS = 50
   LATENT_DIM = 512
   ```

## üß™ Testing Process

### 1. Model Loading
```python
# Load trained model
model = load_model(model_path, latent_dim=512, device='cuda')
```

### 2. Threshold Calculation
The system calculates anomaly thresholds from normal training samples:

```python
def calculate_threshold_from_good_samples(model, data_dir, percentile=90):
    # Load good training samples
    good_samples = load_good_samples(data_dir)
    
    # Calculate reconstruction errors
    errors = []
    for sample in good_samples:
        reconstructed = model(sample)
        error = mse_loss(reconstructed, sample)
        errors.append(error)
    
    # Use percentile as threshold
    threshold = np.percentile(errors, percentile)
    return threshold
```

### 3. Anomaly Detection Pipeline

#### For PaDiM:
1. **Feature Extraction**: Extract features from test image
2. **Mahalanobis Distance**: Calculate distance from learned distribution
3. **Anomaly Map**: Generate pixel-level anomaly scores
4. **Classification**: Compare with threshold for binary decision

#### For Autoencoder:
1. **Preprocessing**: Normalize and resize input image
2. **Reconstruction**: Pass through encoder-decoder network
3. **Error Calculation**: Compute MSE between original and reconstructed
4. **Classification**: Compare reconstruction error with threshold

### 4. Result Interpretation

The system provides comprehensive results:

```python
{
    "reconstruction_error": 0.0156,      # Quantitative anomaly score
    "is_defective": True,                # Binary classification
    "threshold": 0.0123,                 # Decision threshold
    "confidence": 0.0033,                # |error - threshold|
    "anomaly_map": [[...]]               # Pixel-level anomaly scores
}
```

## üîß Model Implementations

### PaDiM Implementation
- **Feature Extractor**: ResNet-18 pretrained on ImageNet
- **Patch Size**: 8x8 patches for spatial modeling
- **Distribution**: Multivariate Gaussian per patch location
- **Advantages**: Fast inference, interpretable results, no training required

### Autoencoder Implementation
- **Architecture**: Symmetric encoder-decoder with skip connections
- **Loss Function**: Mean Squared Error (MSE)
- **Optimization**: Adam optimizer with learning rate scheduling
- **Advantages**: End-to-end learnable, good reconstruction quality

## üåê API and Web Interface

### REST API Endpoints

1. **Model Management**
   - `POST /api/load_model`: Load and configure model
   - `GET /api/status`: Check model status

2. **Inference**
   - `POST /api/test_image`: Test single image
   - `POST /api/batch_test`: Test multiple images

### Web Interface Features

- **Interactive Dashboard**: Real-time model status and configuration
- **File Upload**: Drag-and-drop image testing
- **Results Visualization**: Anomaly maps and detailed metrics
- **Threshold Tuning**: Interactive threshold adjustment

## üê≥ Docker Setup

The system provides containerized deployment with Docker Compose:

### Architecture
```
docker-compose.yml
‚îú‚îÄ‚îÄ training-service    # Model training environment
‚îú‚îÄ‚îÄ inference-api      # REST API service
‚îú‚îÄ‚îÄ web-interface      # Frontend dashboard
‚îî‚îÄ‚îÄ database          # Results storage (optional)
```

### Services Configuration
- **GPU Support**: NVIDIA Docker runtime for training
- **Volume Mounting**: Persistent model and data storage
- **Network**: Internal communication between services
- **Environment**: Configurable through environment variables

## üìä Performance Metrics

### Evaluation Metrics

1. **Classification Metrics**
   - Accuracy: Overall correctness
   - Precision: True positives / (True positives + False positives)
   - Recall: True positives / (True positives + False negatives)
   - F1-Score: Harmonic mean of precision and recall

2. **Anomaly Detection Metrics**
   - AUC-ROC: Area under ROC curve
   - AUC-PR: Area under Precision-Recall curve
   - Optimal Threshold: Best threshold for F1-score

3. **Localization Metrics**
   - Pixel-level AUC: Anomaly localization accuracy
   - Intersection over Union (IoU): Segmentation quality

### Benchmark Results

| Model | Dataset | AUC-ROC | AUC-PR | F1-Score |
|-------|---------|---------|---------|----------|
| PaDiM | Screw   | 0.95    | 0.88    | 0.85     |
| AutoEncoder | Screw | 0.92 | 0.84 | 0.82 |

## üöÄ Installation

### Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- Docker & Docker Compose (for containerized deployment)

### Local Installation
```bash
# Clone repository
git clone <repository-url>
cd MVTec

# Install dependencies
pip install -r requirements.txt

# Download MVTec dataset
# Place dataset in dataset/ directory

# Train model
python main.py

# Run inference API
python api/app.py
```

### Docker Installation
```bash
# Build and run all services
docker-compose up --build

# Run specific service
docker-compose up inference-api
```

## üí° Usage

### Training
```bash
# PaDiM training
python main.py --model padim --dataset screw

# Autoencoder training
python main_2.py --epochs 50 --batch_size 16
```

### Testing
```bash
# Single image test
python test_model.py --single_image path/to/image.png --model_path model.pth

# Dataset evaluation
python test_model.py --data_dir dataset/screw --model_path model.pth
```

### API Usage
```bash
# Start API server
python api/app.py

# Test via curl
curl -X POST -F "image=@test.png" http://localhost:5000/api/test_image
```

## üìà Configuration

### Model Configuration
```python
# config.py
class Config:
    IMAGE_SIZE = 256
    BATCH_SIZE = 16
    LEARNING_RATE = 1e-4
    LATENT_DIM = 512
    THRESHOLD_PERCENTILE = 90
```

### API Configuration
```python
# api/config.py
class APIConfig:
    MAX_FILE_SIZE = 16 * 1024 * 1024  # 16MB
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}
    MODEL_PATH = 'checkpoints/best_model.pth'
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
```

## üîç Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   - Reduce batch size in config
   - Use CPU inference for testing
   - Enable gradient checkpointing

2. **Model Loading Errors**
   - Check model path and format
   - Verify PyTorch version compatibility
   - Ensure correct model architecture

3. **Dataset Issues**
   - Verify dataset structure matches MVTec format
   - Check image formats and sizes
   - Ensure proper train/test split

### Performance Optimization

1. **Training Optimization**
   - Use mixed precision training
   - Implement data parallel training
   - Use efficient data loading

2. **Inference Optimization**
   - Model quantization
   - TensorRT optimization
   - Batch inference for multiple images

## üìù License

This project is licensed under the MIT License - see the LICENSE file for details.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## üìû Support

For questions and support:
- Create an issue on GitHub
- Contact the development team
- Check the documentation wiki